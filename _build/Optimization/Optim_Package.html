---
redirect_from:
  - "/optimization/optim-package"
interact_link: content/Optimization/Optim_Package.ipynb
kernel_name: julia-1.3
has_widgets: false
title: |-
  Optim Package
prev_page:
  url: /Optimization/Gradient_Based_Optimization.html
  title: |-
    Gradient Based Optimization
next_page:
  url: /Graphs/Chapter_Intro.html
  title: |-
    Graphs
suffix: .ipynb

comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---

    <main class="jupyter-page">
    <div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="The-Optim-package">The <code>Optim</code> package<a class="anchor-link" href="#The-Optim-package"> </a></h1><p>For more advanced optimization method, Julia provided a number of state-of-the-art packages.
Here we will consider the <code>Optim</code> package. It has a number of options and features, but
here we will only demonstrate some basic features.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-julia"><pre><span></span><span class="k">using</span> <span class="n">Optim</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In the simplest form, you can solve our optimization problem by only providing
the function $f(x)$ and the initial guess $x_0$. The output shows that it found
a local minimum, and that it used the "Nelder-Mead" method which is derivative
free (zeroth order).</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-julia"><pre><span></span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">=</span> <span class="o">-</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">^</span><span class="mi">2</span><span class="o">/</span><span class="mi">2</span> <span class="o">-</span> <span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">^</span><span class="mi">2</span><span class="o">/</span><span class="mi">4</span> <span class="o">+</span> <span class="mi">3</span><span class="p">)</span> <span class="o">*</span> <span class="n">cos</span><span class="p">(</span><span class="mi">2</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span> <span class="c"># Same as last section</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">optimize</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre> * Status: success

 * Candidate solution
    Minimizer: [3.63e-01, 8.48e-01]
    Minimum:   -2.072854e-01

 * Found with
    Algorithm:     Nelder-Mead
    Initial Point: [0.00e+00, 5.00e-01]

 * Convergence measures
    √(Σ(yᵢ-ȳ)²)/n ≤ 1.0e-08

 * Work counters
    Seconds run:   0  (vs limit Inf)
    Iterations:    31
    f(x) calls:    61
</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If a gradient function is available, a gradient-based solver will be used
automatically (in this case, the L-BFGS method). The <code>inplace=false</code> is used
since our gradient function <code>df</code> returns the gradient instead of modifying it.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-julia"><pre><span></span><span class="k">function</span> <span class="n">df</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> 
    <span class="c"># Same as last section</span>
    <span class="n">a1</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">^</span><span class="mi">2</span><span class="o">/</span><span class="mi">2</span> <span class="o">-</span> <span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">^</span><span class="mi">2</span><span class="o">/</span><span class="mi">4</span> <span class="o">+</span> <span class="mi">3</span>
    <span class="n">a2</span> <span class="o">=</span> <span class="mi">2</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
    <span class="n">b1</span> <span class="o">=</span> <span class="n">cos</span><span class="p">(</span><span class="n">a1</span><span class="p">)</span><span class="o">*</span><span class="n">cos</span><span class="p">(</span><span class="n">a2</span><span class="p">)</span>
    <span class="n">b2</span> <span class="o">=</span> <span class="n">sin</span><span class="p">(</span><span class="n">a1</span><span class="p">)</span><span class="o">*</span><span class="n">sin</span><span class="p">(</span><span class="n">a2</span><span class="p">)</span>
    <span class="k">return</span> <span class="o">-</span><span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">b1</span> <span class="o">-</span> <span class="mi">2</span><span class="n">b2</span><span class="p">,</span> <span class="o">-</span><span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">/</span><span class="mi">2</span><span class="o">*</span><span class="n">b1</span> <span class="o">+</span> <span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span><span class="o">*</span><span class="n">b2</span><span class="p">]</span>
<span class="k">end</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">optimize</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">];</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">false</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre> * Status: success

 * Candidate solution
    Minimizer: [3.63e-01, 8.48e-01]
    Minimum:   -2.072854e-01

 * Found with
    Algorithm:     L-BFGS
    Initial Point: [0.00e+00, 5.00e-01]

 * Convergence measures
    |x - x&#39;|               = 9.09e-07 ≰ 0.0e+00
    |x - x&#39;|/|x&#39;|          = 1.07e-06 ≰ 0.0e+00
    |f(x) - f(x&#39;)|         = 1.19e-12 ≰ 0.0e+00
    |f(x) - f(x&#39;)|/|f(x&#39;)| = 5.74e-12 ≰ 0.0e+00
    |g(x)|                 = 5.19e-10 ≤ 1.0e-08

 * Work counters
    Seconds run:   1  (vs limit Inf)
    Iterations:    8
    f(x) calls:    20
    ∇f(x) calls:   20
</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The method can also be specified explicitly, e.g. the gradient descent method:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-julia"><pre><span></span><span class="n">res</span> <span class="o">=</span> <span class="n">optimize</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="n">GradientDescent</span><span class="p">();</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">false</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre> * Status: success

 * Candidate solution
    Minimizer: [3.63e-01, 8.48e-01]
    Minimum:   -2.072854e-01

 * Found with
    Algorithm:     Gradient Descent
    Initial Point: [0.00e+00, 5.00e-01]

 * Convergence measures
    |x - x&#39;|               = 2.20e-08 ≰ 0.0e+00
    |x - x&#39;|/|x&#39;|          = 2.60e-08 ≰ 0.0e+00
    |f(x) - f(x&#39;)|         = 1.97e-15 ≰ 0.0e+00
    |f(x) - f(x&#39;)|/|f(x&#39;)| = 9.51e-15 ≰ 0.0e+00
    |g(x)|                 = 5.64e-09 ≤ 1.0e-08

 * Work counters
    Seconds run:   0  (vs limit Inf)
    Iterations:    24
    f(x) calls:    65
    ∇f(x) calls:   65
</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If the gradient function is not available, it can be computed using
automatic differentiation:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-julia"><pre><span></span><span class="n">res</span> <span class="o">=</span> <span class="n">optimize</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="n">GradientDescent</span><span class="p">();</span> <span class="n">autodiff</span><span class="o">=:</span><span class="n">forward</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre> * Status: success

 * Candidate solution
    Minimizer: [3.63e-01, 8.48e-01]
    Minimum:   -2.072854e-01

 * Found with
    Algorithm:     Gradient Descent
    Initial Point: [0.00e+00, 5.00e-01]

 * Convergence measures
    |x - x&#39;|               = 2.20e-08 ≰ 0.0e+00
    |x - x&#39;|/|x&#39;|          = 2.60e-08 ≰ 0.0e+00
    |f(x) - f(x&#39;)|         = 1.69e-15 ≰ 0.0e+00
    |f(x) - f(x&#39;)|/|f(x&#39;)| = 8.17e-15 ≰ 0.0e+00
    |g(x)|                 = 5.64e-09 ≤ 1.0e-08

 * Work counters
    Seconds run:   0  (vs limit Inf)
    Iterations:    24
    f(x) calls:    65
    ∇f(x) calls:   65
</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This also works for the Hessian matrix in Newton's method. Note the extremely fast
convergence (number of iterations):</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-julia"><pre><span></span><span class="n">res</span> <span class="o">=</span> <span class="n">optimize</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="n">Newton</span><span class="p">();</span> <span class="n">autodiff</span><span class="o">=:</span><span class="n">forward</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre> * Status: success

 * Candidate solution
    Minimizer: [3.63e-01, 8.48e-01]
    Minimum:   -2.072854e-01

 * Found with
    Algorithm:     Newton&#39;s Method
    Initial Point: [0.00e+00, 5.00e-01]

 * Convergence measures
    |x - x&#39;|               = 4.82e-07 ≰ 0.0e+00
    |x - x&#39;|/|x&#39;|          = 5.69e-07 ≰ 0.0e+00
    |f(x) - f(x&#39;)|         = 1.69e-13 ≰ 0.0e+00
    |f(x) - f(x&#39;)|/|f(x&#39;)| = 8.17e-13 ≰ 0.0e+00
    |g(x)|                 = 2.90e-14 ≤ 1.0e-08

 * Work counters
    Seconds run:   1  (vs limit Inf)
    Iterations:    4
    f(x) calls:    9
    ∇f(x) calls:   9
    ∇²f(x) calls:  4
</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally, we use the BFGS solver using automatic differentiation. This is a widely
used method, since it obtains convergence comparable to Newton's method but without
requiring explicit Hessian matrices:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-julia"><pre><span></span><span class="n">res</span> <span class="o">=</span> <span class="n">optimize</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="n">BFGS</span><span class="p">();</span> <span class="n">autodiff</span><span class="o">=:</span><span class="n">forward</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre> * Status: success

 * Candidate solution
    Minimizer: [3.63e-01, 8.48e-01]
    Minimum:   -2.072854e-01

 * Found with
    Algorithm:     BFGS
    Initial Point: [0.00e+00, 5.00e-01]

 * Convergence measures
    |x - x&#39;|               = 1.09e-05 ≰ 0.0e+00
    |x - x&#39;|/|x&#39;|          = 1.28e-05 ≰ 0.0e+00
    |f(x) - f(x&#39;)|         = 2.91e-10 ≰ 0.0e+00
    |f(x) - f(x&#39;)|/|f(x&#39;)| = 1.41e-09 ≰ 0.0e+00
    |g(x)|                 = 4.04e-09 ≤ 1.0e-08

 * Work counters
    Seconds run:   0  (vs limit Inf)
    Iterations:    6
    f(x) calls:    14
    ∇f(x) calls:   14
</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

 


    </main>
    